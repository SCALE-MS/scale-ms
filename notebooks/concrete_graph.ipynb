{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "source": [
    "# toy graph\n",
    "\n",
    "* Create a basic data node.\n",
    "* Apply a basic data transformation.\n",
    "\n",
    "## check point:\n",
    "\n",
    "* Initialize checkpoint facility in execution context.\n",
    "* Reconcile checkpoint state when building operation.\n",
    "\n",
    "## non-trivial data flow\n",
    "\n",
    "* employ some looping and parallel data flow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%% md\n"
    }
   },
   "source": [
    "The essential difference between an abstract graph and a concrete graph is that\n",
    "the concrete graph has definite and immutable inputs and outputs, whereas an\n",
    "abstract graph may have placeholder inputs and outputs that define connectivity\n",
    "and high-level relationships. This may not be a functional distinction, but\n",
    "just a usage distinction, if nodes may generally be used to prototype equivalent\n",
    "nodes with different inputs, and if running nodes can cause additional nodes\n",
    "to be generated.\n",
    "\n",
    "Checkpoint abstraction should come into play when deserializing the concrete graph.\n",
    "Artifacts associated with prior execution may or may not exist. Nodes will be \n",
    "initialized in an appropriate state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class WorkerContext:\n",
    "    \"\"\"Simple data staging context with file-backed checkpoints.\"\"\"\n",
    "    def __init__(self, working_directory='.'):\n",
    "        self.storage_system = os.path.abspath(working_directory)\n",
    "        # TODO: On initialization, we should check for a clean and usable working directory.\n",
    "        # TODO: We can also preemptively discover existing checkpoint state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_node(context, node):\n",
    "    \"\"\"Register an operation node with the Context.\n",
    "    \n",
    "    Control interface. Used by the execution manager to add tasks to the worker.\n",
    "    \n",
    "    Arguments:\n",
    "        context: Translates work into concrete tasks and manages the resources for execution and data.\n",
    "        node: portable representation of a unit of work.\n",
    "    \"\"\"\n",
    "    builder = node_builder(context, node)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from serialization import Integer64\n",
    "\n",
    "# Question: where can/should we optimize data store and checkpoint writers to\n",
    "#  reduce data transformations? We need to be able to write blocks of serialized\n",
    "#  data, but we should allow optimizations for known data formats.\n",
    "\n",
    "class DataStore:\n",
    "    \"\"\"Abstract interface for stateful data resources.\"\"\"\n",
    "    class ReadHandle:\n",
    "        \"\"\"DataStore handle open for read-only access.\"\"\"\n",
    "\n",
    "    class WriteHandle:\n",
    "        \"\"\"DataStore handle open for writing.\"\"\"\n",
    "\n",
    "    def open(self, mode):\n",
    "        # Check file state.\n",
    "        # If safe, open file and return handle.\n",
    "        pass\n",
    "\n",
    "    def close(self):\n",
    "        # Close and release filehandle, but retain access to the backing resources\n",
    "        # and maximize the ability to reopen the file through a later call.\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class CheckpointPublisher:\n",
    "    \"\"\"Update checkpoint data store with published state.\n",
    "\n",
    "    Provide a standard publishing interface for arbitrary backing store.\n",
    "\n",
    "    Instances are composed for the state data structures of distinct operations.\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "class CheckpointFacility:\n",
    "    \"\"\"Manage file-backed checkpoint state for a concrete node.\n",
    "    \"\"\"\n",
    "    def __init__(self, context, node):\n",
    "        self.uid = get_uid(node)\n",
    "        self.datastore = get_datastore(context, node)\n",
    "\n",
    "    def write(self, state):\n",
    "        \"\"\"Update the checkpoint with new state.\"\"\"\n",
    "\n",
    "    def load(self, receiver):\n",
    "        \"\"\"Apply the checkpoint state to receiver.\n",
    "\n",
    "        This aspect will evolve to a Director that can be applied to an\n",
    "        operation node builder.\n",
    "        \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def get_filesystem(context):\n",
    "    \"\"\"Get the root filesystem node managed by the Context.\"\"\"\n",
    "    return context.storage_system\n",
    "\n",
    "\n",
    "def get_store_type(context, node):\n",
    "    # In a given Context, we could choose a file container type based on data\n",
    "    # type and/or local configuration, such as JSON, pickle, numpy, HDF5, XDR, etc.\n",
    "    return 'numpy'\n",
    "\n",
    "\n",
    "def lock_store(store, owner):\n",
    "    \"\"\"Get data store handle for owner.\n",
    "\n",
    "    Assert ownership of the data store. If the store has no declared owner,\n",
    "    take ownership. If the store has a declared owner, confirm the ownership\n",
    "    matches.\n",
    "\n",
    "    Raises:\n",
    "        OwnershipError: if ownership cannot be established.\n",
    "        ValueError: if *store* or *owner* are invalid.\n",
    "\n",
    "    Returns:\n",
    "        DataStore handle, with ownership established.\n",
    "\n",
    "    Warning:\n",
    "        It is the responsibility of the calling framework to release ownership\n",
    "        of the data store, even in the event of exceptional termination. We will\n",
    "        not bother to make this more robust, because the locking will move to\n",
    "        the level of the Context resources as part of the Session context manager.\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def get_datastore(context, node):\n",
    "    \"\"\"Get the storage handle for a node in this context.\n",
    "\n",
    "    If there is not yet a storage resource for the node, initialize one.\n",
    "    \"\"\"\n",
    "    # Design roadmap\n",
    "    # 1. Initialize or discover valid data store.\n",
    "    #    * create initialized data store in temporary directory with ownership claim.\n",
    "    #    * try to move to canonical location.\n",
    "    #    * if canonical location already exists, reinitialize from existing store\n",
    "    #      and remove temporary data store.\n",
    "    # 2. Take ownership of valid data store.\n",
    "    #    * if canonical location already exists, attempt to lock (create lock directory with ownership metadata)\n",
    "    #    * if lock already exists, produce error output. else, reinitialize from store.\n",
    "    # 3. Remove lock information when WorkerContext releases DataStore handle.\n",
    "\n",
    "    import json\n",
    "    import numpy\n",
    "    import tempfile\n",
    "\n",
    "    storage_system = get_filesystem(context)\n",
    "\n",
    "    uid = node_uid(node)\n",
    "\n",
    "    store_type = get_store_type(context, node)\n",
    "\n",
    "    # 1. Create an initialized data store in a temporary directory.\n",
    "    # Create an initialized data store in a temporary directory.\n",
    "    temp_store = tempfile.mkdtemp(dir=os.path.join(storage_system, 'tmp'))\n",
    "    # describe data store type, fingerprinting details...\n",
    "    metadata = {'uid': uid,\n",
    "                'file_type': store_type}\n",
    "    with open(os.path.join(temp_store, 'metadata.json'), 'w') as fh:\n",
    "        json.dump(fh, metadata)\n",
    "    # \"lock\" the data store for the current context.\n",
    "    owner = {'pid': os.getpid(),\n",
    "              'object': id(context)}\n",
    "    lockfile = os.path.join(temp_store, 'owner')\n",
    "    assert not os.path.exists(lockfile)\n",
    "    with open(lockfile, 'w') as fh:\n",
    "        json.dump(fh, owner)\n",
    "    # Create artifact\n",
    "    npz_file = os.path.join(temp_store, '.'.join([uid, 'npz']))\n",
    "    data = numpy.zeros(shape=node_shape(node), dtype=node_dtype(node))\n",
    "    numpy.savez(npz_file, data=data)\n",
    "\n",
    "\n",
    "    # 2. Try to rename the directory to the canonical name.\n",
    "    #    In order to get an exception, os.rename destination needs to clash with\n",
    "    #    a non-empty directory.\n",
    "    store_path = os.path.join(storage_system, uid)\n",
    "    try:\n",
    "        os.rename(temp_store, store_path)\n",
    "        store = lock_store(store_path, owner)\n",
    "    except OSError as e:\n",
    "        # Ref https://docs.python.org/3/library/os.html#os.rename\n",
    "        # for more specific exceptions.\n",
    "\n",
    "        # 3. If the canonical directory name is already in use, try to take ownership.\n",
    "        try:\n",
    "            # 4. If ownership taken, reinitialize from its contents.\n",
    "            store = lock_store(store_path, owner)\n",
    "        except:\n",
    "            # TODO: What are the exception conditions?\n",
    "            raise\n",
    "\n",
    "    # TODO: Protocol for unlocking the backing store OR lock Context instead.\n",
    "    return store"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"Mock up the Context node builder protocol to test internal details.\"\"\"\n",
    "import json\n",
    "\n",
    "my_array = Integer64([[1, 2], [3, 4]])\n",
    "\n",
    "def receive_node(serialized):\n",
    "    record = Integer64.from_json(serialized)\n",
    "    uid = record.fingerprint().uid()\n",
    "    return {'uid': uid, 'record': json.loads(serialized)}\n",
    "\n",
    "# Receive record of node\n",
    "node = receive_node(my_array.to_json())\n",
    "uid = node['uid']\n",
    "node_record = node['record']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Create a local handle to the node\n",
    "# 1. Check whether the node already exists.\n",
    "# 2. Initialize checkpoint facility for the node.\n",
    "# 3. Allow checkpoint facility to update the node.\n",
    "# 4. Subscribe to needed resources.\n",
    "\n",
    "import json\n",
    "import numpy\n",
    "import tempfile\n",
    "\n",
    "context = WorkerContext()\n",
    "\n",
    "storage_system = get_filesystem(context)\n",
    "\n",
    "store_type = get_store_type(context, node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# 1. Create an initialized data store in a temporary directory.\n",
    "\n",
    "# Make it easy to find the stale temporary directories...\n",
    "tmpdir = os.path.join(storage_system, 'tmp')\n",
    "if not os.path.exists(tmpdir):\n",
    "    os.mkdir(os.path.join(storage_system, 'tmp'))\n",
    "assert os.path.exists(tmpdir)\n",
    "\n",
    "# Create an initialized data store in a temporary directory.\n",
    "temp_store = tempfile.mkdtemp(dir=tmpdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# describe data store type, fingerprinting details...\n",
    "metadata = {'uid': str(uid.hex()),\n",
    "            'file_type': store_type}\n",
    "with open(os.path.join(temp_store, 'metadata.json'), 'w') as fh:\n",
    "    json.dump(obj=metadata, fp=fh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# \"lock\" the data store for the current context.\n",
    "\n",
    "def check_owner(owner, candidate):\n",
    "    for key, value in owner.items():\n",
    "        if not candidate[key] == value:\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "owner = {'pid': int(os.getpid()),\n",
    "          'object': id(context)}\n",
    "lockfile = os.path.join(temp_store, 'owner')\n",
    "if not os.path.exists(lockfile):\n",
    "    with open(lockfile, 'w') as fh:\n",
    "        json.dump(obj=owner, fp=fh)\n",
    "else:\n",
    "    with open(lockfile, 'r') as fh:\n",
    "        candidate = json.load(fh)\n",
    "        assert check_owner(owner, candidate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Create artifact\n",
    "\n",
    "def node_shape(node):\n",
    "    # TODO: generalize.\n",
    "    # Note: The shape is either part of the input metadata or is inferrable from the\n",
    "    # small number of native types.\n",
    "    assert 'record' in node\n",
    "    assert 'input' in node['record']\n",
    "    assert 'data' in node['record']['input']\n",
    "    assert isinstance(node['record']['input']['data'], list)\n",
    "    def nested_list_length(nested_list):\n",
    "        assert isinstance(nested_list, (list, tuple))\n",
    "        yield len(nested_list)\n",
    "        if isinstance(nested_list[0], (list, tuple)):\n",
    "            for length in nested_list_length(nested_list[0]):\n",
    "                yield length\n",
    "            \n",
    "    return tuple(nested_list_length(node['record']['input']['data']))\n",
    "\n",
    "def node_dtype(node):\n",
    "    # TODO: generalize, per graph schema specification.\n",
    "    assert 'record' in node\n",
    "    assert 'operation' in node['record']\n",
    "    assert tuple(node['record']['operation']) == ('scalems', 'Integer64')\n",
    "    return numpy.int64\n",
    "\n",
    "npz_file = os.path.join(temp_store, '.'.join([uid.hex(), 'npz']))\n",
    "data = numpy.zeros(shape=node_shape(node), dtype=node_dtype(node))\n",
    "numpy.savez(npz_file, data=data)\n",
    "assert os.path.exists(npz_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# 2. Try to rename the directory to the canonical name.\n",
    "#    In order to get an exception, os.rename destination needs to clash with\n",
    "#    a non-empty directory.\n",
    "store_path = os.path.join(storage_system, uid)\n",
    "try:\n",
    "    os.rename(temp_store, store_path)\n",
    "    store = lock_store(store_path, owner)\n",
    "except OSError as e:\n",
    "    # Ref https://docs.python.org/3/library/os.html#os.rename\n",
    "    # for more specific exceptions.\n",
    "\n",
    "    # 3. If the canonical directory name is already in use, try to take ownership.\n",
    "    try:\n",
    "        # 4. If ownership taken, reinitialize from its contents.\n",
    "        store = lock_store(store_path, owner)\n",
    "    except:\n",
    "        # TODO: What are the exception conditions?\n",
    "        raise\n",
    "\n",
    "\n",
    "# Accept queries to the node status\n",
    "\n",
    "# Accept subscriptions to the node\n",
    "\n",
    "# Accept a request to publish the node results (trigger execution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
